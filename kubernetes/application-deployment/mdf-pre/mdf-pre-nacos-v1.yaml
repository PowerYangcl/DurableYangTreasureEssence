---
kind: ConfigMap
apiVersion: v1
metadata:
  name: mdf-pre-nacos-config
  namespace: mdf-pre
  annotations:
    kubesphere.io/alias-name: mdf-pre
    kubesphere.io/creator: dev-liu
data:
  application.properties: >

    server.servlet.contextPath=/nacos

    ### Default web server port:

    server.port=8848

    spring.datasource.platform=mysql


    db.num=1


    ### Connect URL of DB:

    db.url.0=jdbc:mysql://mdf-pre-mysql-service-inner.mdf-pre:3306/nacos_config?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC

    db.user.0=root

    db.password.0=XianYue1998@


    ### Connection pool configuration: hikariCP

    db.pool.config.connectionTimeout=30000

    db.pool.config.validationTimeout=10000

    db.pool.config.maximumPoolSize=20

    db.pool.config.minimumIdle=2


    #*************** Naming Module Related Configurations ***************#

    ### Data dispatch task execution period in milliseconds: Will removed on
    v2.1.X, replace with nacos.core.protocol.distro.data.sync.delayMs

    # nacos.naming.distro.taskDispatchPeriod=200


    ### Data count of batch sync task: Will removed on v2.1.X. Deprecated

    # nacos.naming.distro.batchSyncKeyCount=1000


    ### Retry delay in milliseconds if sync task failed: Will removed on v2.1.X,
    replace with nacos.core.protocol.distro.data.sync.retryDelayMs

    # nacos.naming.distro.syncRetryDelay=5000


    ### If enable data warmup. If set to false, the server would accept request
    without local data preparation:

    # nacos.naming.data.warmup=true


    ### If enable the instance auto expiration, kind like of health check of
    instance:

    # nacos.naming.expireInstance=true


    ### will be removed and replaced by `nacos.naming.clean` properties

    nacos.naming.empty-service.auto-clean=true

    nacos.naming.empty-service.clean.initial-delay-ms=50000

    nacos.naming.empty-service.clean.period-time-ms=30000




    ### The delay time before push task to execute from service changed, unit:
    milliseconds.

 

    management.metrics.export.elastic.enabled=false

    #management.metrics.export.elastic.host=http://localhost:9200


    ### Metrics for influx

    management.metrics.export.influx.enabled=false

    #management.metrics.export.influx.db=springboot

    #management.metrics.export.influx.uri=http://localhost:8086

    #management.metrics.export.influx.auto-create-db=true

    #management.metrics.export.influx.consistency=one

    #management.metrics.export.influx.compressed=true


    #*************** Access Log Related Configurations ***************#

    ### If turn on the access log:

    server.tomcat.accesslog.enabled=true


    ### The access log pattern:

    server.tomcat.accesslog.pattern=%h %l %u %t "%r" %s %b %D %{User-Agent}i
    %{Request-Source}i


    ### The directory of access log:

    server.tomcat.basedir=


    #*************** Access Control Related Configurations ***************#

    ### If enable spring security, this option is deprecated in 1.2.0:

    #spring.security.enabled=false


    ### The ignore urls of auth, is deprecated in 1.2.0:

    nacos.security.ignore.urls=/,/error,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-ui/public/**,/v1/auth/**,/v1/console/health/**,/actuator/**,/v1/console/server/**


    ### The auth system to use, currently only 'nacos' and 'ldap' is supported:

    nacos.core.auth.system.type=nacos


    ### If turn on auth system:

    nacos.core.auth.enabled=false


    ### Turn on/off caching of auth information. By turning on this switch, the
    update of auth information would have a 15 seconds delay.

    nacos.core.auth.caching.enabled=true


    ### Since 1.4.1, Turn on/off white auth for user-agent: nacos-server, only
    for upgrade from old version.

    nacos.core.auth.enable.userAgentAuthWhite=false


    ### Since 1.4.1, worked when nacos.core.auth.enabled=true and
    nacos.core.auth.enable.userAgentAuthWhite=false.

    ### The two properties is the white list for auth and used by identity the
    request from other server.

    nacos.core.auth.server.identity.key=serverIdentity

    nacos.core.auth.server.identity.value=security


    ### worked when nacos.core.auth.system.type=nacos

    ### The token expiration in seconds:

    nacos.core.auth.plugin.nacos.token.expire.seconds=18000

    ### The default token:

    nacos.core.auth.plugin.nacos.token.secret.key=SecretKey012345678901234567890123456789012345678901234567890123456789


    ### worked when nacos.core.auth.system.type=ldapï¼Œ{0} is Placeholder,replace
    login username

    #nacos.core.auth.ldap.url=ldap://localhost:389

    #nacos.core.auth.ldap.basedc=dc=example,dc=org

    #nacos.core.auth.ldap.userDn=cn=admin,${nacos.core.auth.ldap.basedc}

    #nacos.core.auth.ldap.password=admin

    #nacos.core.auth.ldap.userdn=cn={0},dc=example,dc=org



    #*************** Istio Related Configurations ***************#

    ### If turn on the MCP server:

    nacos.istio.mcp.server.enabled=false


    #*************** Core Related Configurations ***************#


    ### set the WorkerID manually

    # nacos.core.snowflake.worker-id=


    ### Member-MetaData

    # nacos.core.member.meta.site=

    # nacos.core.member.meta.adweight=

    # nacos.core.member.meta.weight=


    ### MemberLookup

    ### Addressing pattern category, If set, the priority is highest

    # nacos.core.member.lookup.type=[file,address-server]

    ## Set the cluster list with a configuration file or command-line argument

    #
    nacos.member.list=192.168.16.101:8847?raft_port=8807,192.168.16.101?raft_port=8808,192.168.16.101:8849?raft_port=8809

 
    default is 30 minute

    # nacos.core.protocol.raft.data.snapshot_interval_secs=30

    ### raft internal worker threads

    # nacos.core.protocol.raft.data.core_thread_num=8

    ### Number of threads required for raft business request processing

    # nacos.core.protocol.raft.data.cli_service_thread_num=4

    ### raft linear read strategy. Safe linear reads are used by default, that
    is, the Leader tenure is confirmed by heartbeat

    # nacos.core.protocol.raft.data.read_index_type=ReadOnlySafe

    ### rpc request timeout, default 5 seconds

    # nacos.core.protocol.raft.data.rpc_request_timeout_ms=5000


    #*************** Distro Related Configurations ***************#


    ### Distro data sync delay time, when sync task delayed, task will be merged
    for same data key. Default 1 second.

    # nacos.core.protocol.distro.data.sync.delayMs=1000


    ### Distro data sync timeout for one sync data, default 3 seconds.

    # nacos.core.protocol.distro.data.sync.timeoutMs=3000


    ### Distro data sync retry delay time when sync data failed or timeout, same
    behavior with delayMs, default 3 seconds.

    # nacos.core.protocol.distro.data.sync.retryDelayMs=3000


    ### Distro data verify interval time, verify synced data whether expired for
    a interval. Default 5 seconds.

    # nacos.core.protocol.distro.data.verify.intervalMs=5000


    ### Distro data verify timeout for one verify, default 3 seconds.

    # nacos.core.protocol.distro.data.verify.timeoutMs=3000


    ### Distro data load retry delay when load snapshot data failed, default 30
    seconds.

    # nacos.core.protocol.distro.data.load.retryDelayMs=30000
  cluster.conf: |-
    mdf-pre-nacos-v1-0.mdf-pre-nacos.mdf-pre.svc.cluster.local:8848
    mdf-pre-nacos-v1-1.mdf-pre-nacos.mdf-pre.svc.cluster.local:8848
    mdf-pre-nacos-v1-2.mdf-pre-nacos.mdf-pre.svc.cluster.local:8848


---
kind: StatefulSet
apiVersion: apps/v1
metadata:
  name: mdf-pre-nacos-v1
  namespace: mdf-pre
  labels:
    app: mdf-pre-nacos
    version: v1
  annotations:
    kubesphere.io/creator: dev-liu
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mdf-pre-nacos
      version: v1
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: mdf-pre-nacos
        version: v1
      annotations:
        kubesphere.io/creator: dev-liu
        kubesphere.io/imagepullsecrets: '{}'
        logging.kubesphere.io/logsidecar-config: '{}'
    spec:
      volumes:
        - name: host-time
          hostPath:
            path: /etc/localtime
            type: ''
        - name: volume-51myut
          configMap:
            name: mdf-pre-nacos-config
            items:
              - key: application.properties
                path: application.properties
            defaultMode: 420
      containers:
        - name: container-2qi0er
          image: 'registry.cn-beijing.aliyuncs.com/power-matrix/nacos-server'
          ports:
            - name: tcp-8848
              containerPort: 8848
              protocol: TCP
          env:
            - name: MODE
              value: standalone
          resources: {}
          volumeMounts:
            - name: host-time
              readOnly: true
              mountPath: /etc/localtime
            - name: volume-51myut
              readOnly: true
              mountPath: /home/nacos/conf/application.properties
              subPath: application.properties
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          imagePullPolicy: IfNotPresent
      restartPolicy: Always
      terminationGracePeriodSeconds: 30
      dnsPolicy: ClusterFirst
      serviceAccountName: default
      serviceAccount: default
      securityContext: {}
      schedulerName: default-scheduler
  serviceName: mdf-pre-nacos
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0
  revisionHistoryLimit: 10

---
kind: Service
apiVersion: v1
metadata:
  name: mdf-pre-nacos
  namespace: mdf-pre
  labels:
    app: mdf-pre-nacos
    version: v1
  annotations:
    kubesphere.io/alias-name: mdf-pre
    kubesphere.io/creator: dev-liu
    kubesphere.io/serviceType: statefulservice
spec:
  ports:
    - name: tcp-8848
      protocol: TCP
      port: 8848
      targetPort: 8848
  selector:
    app: mdf-pre-nacos
  clusterIP: None
  clusterIPs:
    - None
  type: ClusterIP
  sessionAffinity: None
  ipFamilies:
    - IPv4
  ipFamilyPolicy: SingleStack
  internalTrafficPolicy: Cluster

---
kind: Service
apiVersion: v1
metadata:
  name: mdf-pre-nacos-service-np
  namespace: mdf-pre
  labels:
    app: mdf-pre-nacos-service-np
  annotations:
    kubesphere.io/alias-name: mdf-pre
    kubesphere.io/creator: dev-liu
spec:
  ports:
    - name: http-8848
      protocol: TCP
      port: 8848
      targetPort: 8848
      nodePort: 31940
  selector:
    app: mdf-pre-nacos
    version: v1
  #clusterIP: 10.233.61.53
  #clusterIPs:
  #  - 10.233.61.53
  type: NodePort
  sessionAffinity: None
  externalTrafficPolicy: Cluster
  ipFamilies:
    - IPv4
  ipFamilyPolicy: SingleStack
  internalTrafficPolicy: Cluster
















